# ç»“æ„åŒ–å“åº”ä½¿ç”¨æŒ‡å—

## ğŸ“Š æ¦‚è§ˆ

`langchain-bocha` å·¥å…·è¿”å›æ ‡å‡†çš„å­—å…¸æ ¼å¼ï¼ˆJSONå¯åºåˆ—åŒ–ï¼‰ï¼Œä½†æä¾›äº† `SearchResponse` Pydantic æ¨¡å‹ï¼Œä½ å¯ä»¥é€‰æ‹©å°†å­—å…¸è½¬æ¢ä¸ºç»“æ„åŒ–å¯¹è±¡ä»¥è·å¾—ç±»å‹å®‰å…¨ã€‚

## ğŸ”„ å·¥ä½œåŸç†

1. **å†…éƒ¨å¤„ç†**: APIå“åº”è¢«è§£æä¸º `SearchResponse` å¯¹è±¡è¿›è¡ŒéªŒè¯
2. **è¿”å›æ ¼å¼**: å·¥å…·è¿”å›å­—å…¸ï¼ˆ`result.to_dict()`ï¼‰ï¼Œç¡®ä¿ JSON å¯åºåˆ—åŒ–
3. **å¯é€‰è½¬æ¢**: ä½ å¯ä»¥æ‰‹åŠ¨è½¬æ¢ä¸º `SearchResponse` å¯¹è±¡ä»¥è·å¾—ç±»å‹å®‰å…¨

## âœ¨ æ ¸å¿ƒä¼˜åŠ¿

### 1. å…¼å®¹æ€§
```python
from langchain_bocha import BochaSearch

tool = BochaSearch()
result_dict = tool.invoke({"query": "AI"})

# è¿”å›å­—å…¸ï¼ŒJSONå¯åºåˆ—åŒ–ï¼Œä¸LangChainå®Œç¾å…¼å®¹
# å¯ä»¥åœ¨Agentä¸­ä½¿ç”¨ï¼Œæ— éœ€æ‹…å¿ƒåºåˆ—åŒ–é—®é¢˜
```

### 2. ç±»å‹å®‰å…¨ï¼ˆå¯é€‰ï¼‰
```python
from langchain_bocha import BochaSearch, SearchResponse

tool = BochaSearch()
result_dict = tool.invoke({"query": "AI"})

# è½¬æ¢ä¸ºç»“æ„åŒ–å¯¹è±¡
result = SearchResponse(**result_dict)

# IDE æä¾›å®Œæ•´çš„è‡ªåŠ¨è¡¥å…¨å’Œç±»å‹æ£€æŸ¥
result.query_context.original_query  # âœ… ç±»å‹æ­£ç¡®
result.web_pages.value[0].name      # âœ… ç±»å‹æ­£ç¡®
```

### 3. æ•°æ®éªŒè¯
```python
# å†…éƒ¨ä½¿ç”¨ Pydantic è‡ªåŠ¨éªŒè¯æ‰€æœ‰å­—æ®µ
# åªæœ‰åˆæ³•çš„APIå“åº”æ‰ä¼šè¢«è¿”å›
```

### 3. æ¸…æ™°çš„æ–‡æ¡£
```python
# æ¯ä¸ªå­—æ®µéƒ½æœ‰ç±»å‹æç¤º
class WebPageValue(BaseModel):
    name: str                       # å¿…å¡«å­—æ®µ
    url: str                        # å¿…å¡«å­—æ®µ
    summary: Optional[str] = None   # å¯é€‰å­—æ®µ
```

## ğŸ“š å®Œæ•´çš„æ•°æ®ç»“æ„

### SearchResponse
```python
class SearchResponse:
    type: str                                    # "_type" in API
    query_context: QueryContext                  # "queryContext" in API
    web_pages: Optional[WebSearchWebPages]       # "webPages" in API
    images: Optional[WebSearchImages]            # "images" in API
    videos: Optional[WebSearchVideos]            # "videos" in API
```

### WebSearchWebPages
```python
class WebSearchWebPages:
    web_search_url: Optional[str]
    total_estimated_matches: Optional[int]       # æ€»åŒ¹é…æ•°
    value: List[WebPageValue]                    # æœç´¢ç»“æœåˆ—è¡¨
    some_results_removed: Optional[bool]         # æ˜¯å¦è¿‡æ»¤
```

### WebPageValue
```python
class WebPageValue:
    # å¿…å¡«å­—æ®µ
    name: str                                    # æ ‡é¢˜
    url: str                                     # URL
    snippet: str                                 # æ‘˜è¦
    
    # å¯é€‰å­—æ®µ
    id: Optional[str]
    display_url: Optional[str]                   # å±•ç¤ºURL
    summary: Optional[str]                       # è¯¦ç»†æ‘˜è¦ï¼ˆsummary=trueæ—¶ï¼‰
    site_name: Optional[str]                     # ç½‘ç«™å
    site_icon: Optional[str]                     # ç½‘ç«™å›¾æ ‡
    date_published: Optional[str]                # å‘å¸ƒæ—¶é—´
    date_last_crawled: Optional[str]             # çˆ¬å–æ—¶é—´
    cached_page_url: Optional[str]               # ç¼“å­˜URL
    language: Optional[str]                      # è¯­è¨€
```

### ImageValue
```python
class ImageValue:
    content_url: Optional[str]                   # å›¾ç‰‡URL
    thumbnail_url: Optional[str]                 # ç¼©ç•¥å›¾URL
    name: Optional[str]                          # æ ‡é¢˜
    width: Optional[int]                         # å®½åº¦
    height: Optional[int]                        # é«˜åº¦
    host_page_url: Optional[str]                 # æ‰€åœ¨é¡µé¢URL
```

## ğŸ’» ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨ï¼ˆå­—å…¸æ–¹å¼ï¼‰
```python
from langchain_bocha import BochaSearch

tool = BochaSearch(count=5, summary=True)
result_dict = tool.invoke({"query": "äººå·¥æ™ºèƒ½"})

# å­—å…¸è®¿é—®
query = result_dict["queryContext"]["originalQuery"]
print(f"æŸ¥è¯¢: {query}")

# è®¿é—®ç½‘é¡µç»“æœ
if "webPages" in result_dict and result_dict["webPages"]:
    web_pages = result_dict["webPages"]
    total = web_pages.get("totalEstimatedMatches", 0)
    print(f"æ‰¾åˆ°çº¦ {total:,} ä¸ªç»“æœ")
    
    for page in web_pages.get("value", []):
        print(f"æ ‡é¢˜: {page['name']}")
        print(f"URL: {page['url']}")
        print(f"æ‘˜è¦: {page['snippet']}")
```

### ç±»å‹å®‰å…¨ä½¿ç”¨ï¼ˆç»“æ„åŒ–å¯¹è±¡ï¼‰
```python
from langchain_bocha import BochaSearch, SearchResponse

tool = BochaSearch(count=5, summary=True)
result_dict = tool.invoke({"query": "äººå·¥æ™ºèƒ½"})

# è½¬æ¢ä¸ºç»“æ„åŒ–å¯¹è±¡
result = SearchResponse(**result_dict)

# ç±»å‹å®‰å…¨çš„è®¿é—®
print(f"æŸ¥è¯¢: {result.query_context.original_query}")

# è®¿é—®ç½‘é¡µç»“æœ
if result.web_pages:
    print(f"æ‰¾åˆ°çº¦ {result.web_pages.total_estimated_matches:,} ä¸ªç»“æœ")
    
    for page in result.web_pages.value:
        print(f"æ ‡é¢˜: {page.name}")
        print(f"URL: {page.url}")
        print(f"æ‘˜è¦: {page.snippet}")
        
        # å¯é€‰å­—æ®µéœ€è¦æ£€æŸ¥
        if page.summary:
            print(f"è¯¦ç»†æ‘˜è¦: {page.summary}")
        if page.site_name:
            print(f"æ¥æº: {page.site_name}")
        if page.date_published:
            print(f"å‘å¸ƒæ—¶é—´: {page.date_published}")
```

### å›¾ç‰‡ç»“æœ
```python
if result.images and result.images.value:
    print(f"æ‰¾åˆ° {len(result.images.value)} å¼ å›¾ç‰‡")
    
    for img in result.images.value:
        if img.content_url:
            print(f"å›¾ç‰‡: {img.name}")
            print(f"URL: {img.content_url}")
            print(f"å°ºå¯¸: {img.width}x{img.height}")
```

### è½¬æ¢ä¸ºå­—å…¸
```python
# å¦‚æœéœ€è¦å­—å…¸æ ¼å¼ï¼ˆä¾‹å¦‚ç”¨äºJSONåºåˆ—åŒ–ï¼‰
result_dict = result.to_dict()

# ä½¿ç”¨åŸå§‹APIå­—æ®µå
assert "_type" in result_dict
assert "queryContext" in result_dict
assert "webPages" in result_dict
```

### ä¸Agenté›†æˆ
```python
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_bocha import BochaSearch, SearchResponse

llm = ChatOpenAI(model="gpt-4o")
tool = BochaSearch()

# Agentä¼šè‡ªåŠ¨å¤„ç†ç»“æ„åŒ–å“åº”
agent_executor = AgentExecutor(
    agent=create_openai_tools_agent(llm, [tool], prompt),
    tools=[tool]
)

response = agent_executor.invoke({"messages": [...]})
```

## ğŸ”„ å­—æ®µåæ˜ å°„

Pydanticä½¿ç”¨Pythonå‘½åè§„èŒƒï¼ˆsnake_caseï¼‰ï¼Œä½†å¯ä»¥æ— ç¼æ˜ å°„åˆ°APIå­—æ®µåï¼ˆcamelCaseï¼‰ï¼š

| Python å±æ€§ | API å­—æ®µå |
|------------|------------|
| `type` | `_type` |
| `query_context` | `queryContext` |
| `original_query` | `originalQuery` |
| `web_pages` | `webPages` |
| `total_estimated_matches` | `totalEstimatedMatches` |
| `display_url` | `displayUrl` |
| `site_name` | `siteName` |
| `site_icon` | `siteIcon` |
| `date_published` | `datePublished` |
| `date_last_crawled` | `dateLastCrawled` |
| `content_url` | `contentUrl` |
| `thumbnail_url` | `thumbnailUrl` |

## ğŸ“ æœ€ä½³å®è·µ

### 1. ä½¿ç”¨ç±»å‹æ³¨è§£
```python
result: SearchResponse = tool.invoke({"query": "..."})
```

### 2. æ£€æŸ¥å¯é€‰å­—æ®µ
```python
if result.web_pages and result.web_pages.value:
    for page in result.web_pages.value:
        if page.summary:  # æ£€æŸ¥å¯é€‰å­—æ®µ
            print(page.summary)
```

### 3. åˆ©ç”¨IDEè‡ªåŠ¨è¡¥å…¨
```python
# è¾“å…¥ result. åï¼ŒIDEä¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨å±æ€§
result.web_pages.value[0].  # æ˜¾ç¤ºWebPageValueçš„æ‰€æœ‰å­—æ®µ
```

### 4. é”™è¯¯å¤„ç†
```python
try:
    result = tool.invoke({"query": "..."})
    if result.web_pages:
        print(f"æ‰¾åˆ° {len(result.web_pages.value)} ä¸ªç»“æœ")
except Exception as e:
    print(f"æœç´¢å¤±è´¥: {e}")
```

## ğŸ”§ è¿ç§»æŒ‡å—

å·¥å…·ç°åœ¨è¿”å›å­—å…¸æ ¼å¼ï¼Œä¸åšæŸ¥APIçš„å“åº”ç»“æ„ä¸€è‡´ã€‚

### å­—å…¸è®¿é—®ï¼ˆæ¨èï¼‰
```python
from langchain_bocha import BochaSearch

tool = BochaSearch()
result_dict = tool.invoke({"query": "..."})

# ä½¿ç”¨åšæŸ¥APIçš„å­—æ®µå
query = result_dict["queryContext"]["originalQuery"]
if "webPages" in result_dict:
    for page in result_dict["webPages"]["value"]:
        print(page["name"])  # æ ‡é¢˜
        print(page["url"])   # URL
```

### ç±»å‹å®‰å…¨è®¿é—®ï¼ˆå¯é€‰ï¼‰
```python
from langchain_bocha import BochaSearch, SearchResponse

tool = BochaSearch()
result_dict = tool.invoke({"query": "..."})

# è½¬æ¢ä¸ºç»“æ„åŒ–å¯¹è±¡
result = SearchResponse(**result_dict)

# ä½¿ç”¨Pythoné£æ ¼çš„å±æ€§å
query = result.query_context.original_query
if result.web_pages:
    for page in result.web_pages.value:
        print(page.name)  # ç±»å‹å®‰å…¨ï¼ŒIDEè‡ªåŠ¨è¡¥å…¨
```

## ğŸ“¦ å¯¼å‡ºçš„ç±»å‹

æ‰€æœ‰ç±»å‹éƒ½å¯ä»¥ä»ä¸»åŒ…å¯¼å…¥ï¼š

```python
from langchain_bocha import (
    BochaSearch,           # ä¸»å·¥å…·ç±»
    SearchResponse,        # æœç´¢å“åº”
    WebPageValue,          # ç½‘é¡µç»“æœ
    WebSearchWebPages,     # ç½‘é¡µç»“æœé›†åˆ
    ImageValue,            # å›¾ç‰‡ç»“æœ
    VideoValue,            # è§†é¢‘ç»“æœ
    WebSearchImages,       # å›¾ç‰‡ç»“æœé›†åˆ
    WebSearchVideos,       # è§†é¢‘ç»“æœé›†åˆ
    QueryContext,          # æŸ¥è¯¢ä¸Šä¸‹æ–‡
)
```

## ğŸš€ æ€§èƒ½

ç»“æ„åŒ–å“åº”ä¸ä¼šå½±å“æ€§èƒ½ï¼š

- âœ… Pydantic v2 ä½¿ç”¨ Rust å®ç°ï¼Œè§£æé€Ÿåº¦æå¿«
- âœ… éªŒè¯å‘ç”Ÿåœ¨å¯¹è±¡åˆ›å»ºæ—¶ï¼Œè®¿é—®å±æ€§æ— é¢å¤–å¼€é”€
- âœ… å†…å­˜å ç”¨ä¸å­—å…¸ç›¸å½“

## ğŸ› è°ƒè¯•æŠ€å·§

```python
# æ‰“å°å®Œæ•´çš„å“åº”ç»“æ„
print(result.model_dump_json(indent=2))

# æŸ¥çœ‹æ‰€æœ‰å­—æ®µ
print(result.model_fields.keys())

# è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿æ£€æŸ¥
result_dict = result.to_dict()
import json
print(json.dumps(result_dict, indent=2, ensure_ascii=False))
```

